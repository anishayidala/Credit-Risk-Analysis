# -*- coding: utf-8 -*-
"""Cross validation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qyxtru62rbDfIaBghDBiVt9wR5YshmVP
"""

import pandas as pd
import numpy as np
from sklearn import  tree
from sklearn.ensemble import  RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics

#reading data from train file
traindata = pd.read_csv("./Train.csv")

#check for null values
traindata.isnull().sum()

traindata

#renaming columns for better understanding
traindata = traindata.rename(columns={'id':'id','F1': 'degreeyearscompletion', 'F2': 'hoursworkedperweek','F3': 'Relationship', 'F4': 'OccupationType','F5': 'Gains', 'F6': 'Loss','F7': 'MaritalStatus', 'F8': 'EmploymentType','F9': 'EducationType', 'F10': 'Race','F11': 'Male/Female', 'credit': 'creditscore' })

traindata

#eliminating features from the traindata
traindata = traindata.drop(["id"],axis=1)
traindata = traindata.drop(["EducationType"],axis=1)
traindata= traindata.drop(["MaritalStatus"],axis=1)

traindata

testdata = pd.read_csv("./Test.csv")

#check for null values
testdata.isnull().sum()

#renaming columns for better understanding
testdata = testdata.rename(columns={'id':'id','F1': 'degreeyearscompletion', 'F2': 'hoursworkedperweek','F3': 'Relationship', 'F4': 'OccupationType','F5': 'Gains', 'F6': 'Loss','F7': 'MaritalStatus', 'F8': 'EmploymentType','F9': 'EducationType', 'F10': 'Race','F11': 'Male/Female'})

testdata

#eliminating features from the testdata
testdata = testdata.drop(["id"],axis=1)
testdata = testdata.drop(["EducationType"],axis=1)
testdata= testdata.drop(["MaritalStatus"],axis=1)

testdata

#normalized function to scale features
def normalized(A):
    A = (A- np.min(A))/ (np.max(A) - np.min(A))
    return A

#selecting continuous variables
continuous_values_train = traindata[['degreeyearscompletion','hoursworkedperweek','Gains','Loss']]

continuous_values_test = testdata[['degreeyearscompletion' , 'hoursworkedperweek','Gains','Loss']]

normalized_traindata = normalized(continuous_values_train)

normalized_testdata = normalized(continuous_values_test)

bin = [-0.1, 0.25, 0.50, 0.75, 1]

# continuous variables to categorical variables and onehot encoding
train_f1 =  pd.cut(normalized_traindata['degreeyearscompletion'],bins = bin)
train_f2 =  pd.cut(normalized_traindata['hoursworkedperweek'],bins = bin)
train_f5 =  pd.cut(normalized_traindata['Gains'],bins = bin)
train_f6 =  pd.cut(normalized_traindata['Loss'],bins = bin)

dummy_data_train =  pd.concat([train_f1, train_f2, train_f5, train_f6, traindata[['Race', 'Male/Female']]], axis =1)

test_f1 =  pd.cut(normalized_testdata['degreeyearscompletion'],bins = bin)
test_f2 =  pd.cut(normalized_testdata['hoursworkedperweek'],bins = bin)
test_f5 =  pd.cut(normalized_testdata['Gains'],bins = bin)
test_f6 =  pd.cut(normalized_testdata['Loss'],bins = bin)

dummy_data_test =  pd.concat([test_f1, test_f2, test_f5, test_f6, testdata[['Race', 'Male/Female']]], axis =1)

onehot_train = pd.get_dummies(dummy_data_train)

#splitting train data to fit to the model
X = pd.concat([traindata[['Relationship', 'OccupationType', 'EmploymentType']], onehot_train], axis =1)
y = traindata['creditscore']

onehot_test = pd.get_dummies(dummy_data_test)

#test data to make predictions on
Xtest = pd.concat([testdata[['Relationship', 'OccupationType', 'EmploymentType']], onehot_test], axis =1)

#splitting train data using test train split for cross validation
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1)

#Decision tree classifier
classifier = tree.DecisionTreeClassifier(max_depth= 25, min_samples_split = 50)

classifier = classifier.fit(X_train,y_train)
y_pred = classifier.predict(X_test)

actual_predict=classifier.predict(X_test)
print("Accuracy:",metrics.f1_score(y_test, y_pred))

#random forest classifier
clf=RandomForestClassifier(n_estimators=100)
clf.fit(X_train,y_train)
y_pred=clf.predict(X_test)
print("Accuracy:",metrics.f1_score(y_test, y_pred))

#xgb classifier
!pip install -q xgboost
from xgboost import XGBClassifier
model = XGBClassifier(scale_pos_weight=1,learning_rate=0.1,colsample_bytree = 0.6,subsample = 0.8,objective='binary:logistic',n_estimators=2000, reg_alpha = 0.5,max_depth=6, gamma=10)

X_train

# renaming columns to fit to xgb model
X_train = X_train.rename(columns={'degreeyearscompletion_(-0.1, 0.25]':'degreeyearscompletion1','degreeyearscompletion_(0.25, 0.5]':'degreeyearscompletion2','degreeyearscompletion_(0.5, 0.75]':'degreeyearscompletion3','degreeyearscompletion_(0.75, 1.0]':'degreeyearscompletion4','hoursworkedperweek_(-0.1, 0.25]':'hoursworkedperweek1','hoursworkedperweek_(0.25, 0.5]':'hoursworkedperweek2','hoursworkedperweek_(0.5, 0.75]':'hoursworkedperweek3','hoursworkedperweek_(0.75, 1.0]':'hoursworkedperweek4','Gains_(-0.1, 0.25]':'Gains1','Gains_(0.25, 0.5]':'Gains2','Gains_(0.5, 0.75]':'Gains3','Gains_(0.75, 1.0]':'Gains4','Loss_(-0.1, 0.25]':'Loss1','Loss_(0.25, 0.5]':'Loss2','Loss_(0.5, 0.75]':'Loss3','Loss_(0.75, 1.0]':'Loss4'})

X_test = X_test.rename(columns={'degreeyearscompletion_(-0.1, 0.25]':'degreeyearscompletion1','degreeyearscompletion_(0.25, 0.5]':'degreeyearscompletion2','degreeyearscompletion_(0.5, 0.75]':'degreeyearscompletion3','degreeyearscompletion_(0.75, 1.0]':'degreeyearscompletion4','hoursworkedperweek_(-0.1, 0.25]':'hoursworkedperweek1','hoursworkedperweek_(0.25, 0.5]':'hoursworkedperweek2','hoursworkedperweek_(0.5, 0.75]':'hoursworkedperweek3','hoursworkedperweek_(0.75, 1.0]':'hoursworkedperweek4','Gains_(-0.1, 0.25]':'Gains1','Gains_(0.25, 0.5]':'Gains2','Gains_(0.5, 0.75]':'Gains3','Gains_(0.75, 1.0]':'Gains4','Loss_(-0.1, 0.25]':'Loss1','Loss_(0.25, 0.5]':'Loss2','Loss_(0.5, 0.75]':'Loss3','Loss_(0.75, 1.0]':'Loss4'})

model.fit(X_train,y_train)

y_pred=model.predict(X_test)

print("F1_Score:",metrics.f1_score(y_test, y_pred))

#SVM model
from sklearn.svm import SVC

svclassifier = SVC(kernel='rbf')
svclassifier.fit(X_train, y_train)
ysvm = svclassifier.predict(X_test)
print("Accuracy:",metrics.f1_score(y_test, ysvm))